---
title: "SheddingLagDistribution"
author: "Marlin"
date: "7/22/2021"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: inline
---

```{r set up markdown settings, echo=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)

```

```{r Start enviroment, message=FALSE, warning=FALSE}
library(ggpubr)
library(dplyr)
library(forecast)
library(lmtest)
library(lubridate)
library(limma)
library(zoo)

#Data Files and prep work
source("../../Scripts/GenPlotMaking.R")
source("../../Scripts/WasteWaterDataProccess.R")
source("../../Scripts/CassesDataProccess.R")
source("../../Scripts/HelperFunctions.R")

```

```{r DF Set Up}
PathStarter="Z:/"

LatMMSDFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/MMSD_Cases.csv")
LatSpringDormFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/SpringSemester_CasesByDorm.TSV")
LatFallDormFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/FallSemester_CasesByDorm.TSV")

LIMSFN <- paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/WATERMICRO_WW_COVID-2021-06-30 17 40.xlsx")

HFGCasesFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/HighFreq_CaseData_2021-05-07.csv")


LatCaseDF <- CovidDataPARSER(LatSpringDormFN,LatFallDormFN,MMSDFN = LatMMSDFN)%>%
  filter(!is.na(Site))%>%
  select(Date,Site,Cases,Tests,Per_pos)

HFGCaseDF <- HFGCasesPARSER(FN = HFGCasesFN)%>%
  filter(!is.na(Site))%>%
  mutate(Tests=NA,Per_pos=NA)%>%
  select(Date,Site,Cases=ReportedCases,Tests,Per_pos)%>%
  mutate(Cases = ifelse(Cases==-999,2.5,Cases))%>%
  filter(Site!="Madison")

FullCase <- rbind(HFGCaseDF,LatCaseDF)

LIMSFullDF <- LIMSDataPARSER(LIMSFN)%>%
  select(Date,Site, BCoV, N1,N1Error,N2, N2Error,PMMoV,Pop,FlowRate)

CaseSum=FullCase%>%
  filter(!is.na(Cases))%>%
  group_by(Site)%>%
  summarise(NCase=n())

N1Sum=LIMSFullDF%>%
  filter(!is.na(N1))%>%
  group_by(Site)%>%
  summarise(NN1=n())

DataComp <- inner_join(CaseSum,N1Sum,by=c("Site"))%>%
  mutate(Dif=NCase-NN1,min=ifelse(NCase<NN1,NCase,NN1))
LowCaseDataPoints <- DataComp%>%
  filter(Dif<0)

```


```{r CaseSmoothing, include=FALSE}
#return( RollPerPos(CaseDF,"Cases","Tests",Facet="Site"))
library(limma)
DataPrep <- function(DF,SiteS=NA,keep=c()){
  if(!is.na(SiteS)){
    FilteredVec1 <- filter(DF,Site==SiteS)
  }else{
    FilteredVec1 <- DF
  }
  
  FullDayDF <- data.frame(Date=seq(min(FilteredVec1$Date),
                                   max(FilteredVec1$Date),1))
  ReadyDF <- full_join(FullDayDF,FilteredVec1, by = c("Date"))%>%
    fill(one_of(keep), .direction = "down")%>%
    mutate(Site=SiteS)%>%
    select(Date,one_of(keep),Site,)
  return(ReadyDF)
}


DFSmoothingFNC <- function(CaseDF,
                           SiteS,
                           PreRoll=FALSE,
                           Weights=dgamma(1:21,scale =5.028338,shape =2.332779)){
  #5.028338
  #2.332779
  
  FullDayDF <- DataPrep(CaseDF,"Cases",SiteS=SiteS)
  
  if(PreRoll){
    FullDayDF <- FullDayDF%>%
      group_by(Site)%>%
      mutate(Cases2 = c(rep(NA,6),
                    rollapply(Cases,width=7,
                              FUN=mean,
                              na.rm = TRUE)))
  }else{
    FullDayDF <- FullDayDF%>%
      mutate(Cases2=Cases)
  }
  FullDayDF <- FullDayDF%>%
    group_by(Site)%>%
    mutate(Cases2 = c(rep(NA,20),
                    rollapply(Cases2,width=21,FUN=weighted.mean,
                          w=Weights,
                          na.rm = TRUE)))
  return(FullDayDF)
}

DFLoessFNC <- function(N1DF,SiteS){

    ReadyDF <- DataPrep(N1DF,keep=c("N1"),SiteS=SiteS)
    
    loessFit(y=log(ReadyDF$N1),
             x=ReadyDF$Date,
             span=.125,
             min.weight=0,
             max.weight=1e5,
             iterations=20)$fitted
}

  #5.028338
scale =5.028338
  #2.332779
shape =2.332779
  
plot(dgamma(1:21,scale =scale,shape =shape), 
            main="Gamma Distribution with mean = 11.73 days and SD = 7.68",
            ylab = "Weight",
            xlab = "Lag")


plot(c(rep(0,10),dgamma(1:21,scale =scale,shape =shape)[11:21]), 
            main="Gamma Distribution with mean = 11.73 days and SD = 7.68",
            ylab = "Weight",
            xlab = "Lag")


```


```{R TSPliting}

#library(smooth)
#sma(MergedDF[,8], h=7)

# fit = Arima(CasesTSVec, xreg=loessPred, order=c(2,1,0))
# 
# cbind("Regression Errors" = residuals(fit, type="regression"),
#       "ARIMA errors" = residuals(fit, type="innovation")) %>%
#   autoplot(facets=TRUE)
# checkresiduals(fit)
#
 

#alt y axis
#x axis labled as date
#control color so they are not so light
#2)Show original data as bar graph?
#Make it clear its Madison/Title that explains
#few people have done SLD
```

```{r Formal Work, include=FALSE}
# IndependentVec <- diff(loessPred)
# DependentVec <- diff(CasesTSVec)
# 
# ccfvalues2  <-  ccf(IndependentVec,DependentVec,type = c("correlation"),na.action = na.pass)
# ccfvalues2  <-  ccf(loessPred,CasesTSVec,type = c("correlation"),na.action = na.pass)
# 
# alldata1 <- ts.union(Pred = diff(CasesTSVec),N1Norm = diff(loessPred),
#                          N1TSVec,
#                          N1A=stats::lag(diff(loessPred),1),
#                          N1B=stats::lag(diff(loessPred),10),
#                          N1C=stats::lag(diff(loessPred)))
# 
# 
# tryit1a  <- lm(Pred~N1B, data = alldata1)
# 
# summary(tryit1a)
# #plot(tryit1a)
# acf(residuals(tryit1a))
```

```{r}
#Do for non interceptor data
 
#Transformation to stabilize scale
 
 
#1)Make overlay plot function
#a)normal comp
#b)first difference
#c)P8 version
#compare smooth vs Smooth  ccf
#show all smooth Unsmooth combos
#look for best gamma
 
 
#CCF
#broke it into 2 parts
#CCF of SLD vs raw N1
 
#ccf(CasesTSVec,)
 
#some pipeline to optimize
#What did the original paper do? are we doing the same thing
#case reported at day A
#What we want: when person A became infected
#What we expect: SLD leads Cases
#infected a week and a half ago - some people are still shedding
#if looking at cases you have 3 gammas 
#Cases ~ 2 gamma ~ infected ~ 1 gamma ~ still shedding 
 
#1) Focus on 2 or 3 plots give very clear heuristic picture. in form that does not need words
 
#2)CCF that gives metric behind heuristic
 
#3)
 #FullCase
```
 
 
```{r Ploting Fnc} 
#library(dynlm)

IsFull <- function(DF){
  return(length(DF$Date)==max(DF$Date)-min(DF$Date)+1)
}

TSPloting <- function(PlotingTS,SourceDF,DepName,IndName,FullPlot=TRUE,SubTitle=NA,FirstDif=FALSE){
  if(FirstDif){
    PlotingTS[[2]] <- diff(PlotingTS[[2]])
    PlotingTS[[1]] <- diff(PlotingTS[[1]])
    Lab <- paste("First Diffrence of", DepName, "and", IndName)
  }else{
    Lab <- paste("Visual relationship of", DepName, "and", IndName)
  }
  plot.new()
  par(mar = c(5, 4, 4, 4) + 0.3)           

  if(FullPlot){
    plot.ts(rollmean(exp(PlotingTS[[4]]), 7,align="right",fill = NA),
            col = "steelblue3", 
            axes = FALSE, 
            xlab = "", 
            ylab = "",
            xaxt = "n",
            log="y")
    
    axis(side = 4, col.axis="blue")
    
    par(new = TRUE)  
    plot.ts(rollmean(PlotingTS[[3]], 7,align="right",fill = NA),
            col = "hotpink",        
       axes = FALSE, xlab = "", ylab = "",xaxt = "n")
    
    par(new = TRUE)  
    plot.ts(exp(PlotingTS[[2]]),
            col = "blue",        
       axes = FALSE, 
       xlab = "", 
       ylab = "",
       log = 'y',
       xaxt = "n")
  }else{
    plot.ts(exp(PlotingTS[[2]]), 
          col = "blue", 
          axes = FALSE,
          main=Lab,
          ylab="",
          sub=SubTitle,
          log = 'y',
          xaxt = "n")
    axis(side = 4, col.axis="blue")
  }

  par(new = TRUE)                           
  plot.ts(PlotingTS[[1]], col = "red",        
     axes = FALSE, xlab = "", ylab = "",xaxt = "n")

  axis(side = 2, at = pretty(range(PlotingTS[[1]])),col.axis="red")
  mtext("Cases", side = 2, line = 3, col = "red")
  mtext("N1 (GC/L)", side = 4, line = 3, col = "blue")
  if(FullPlot){
    legendNames <- c("SLD Cases","7 MA Cases","Loess Smoothing","7 MA N1")
    legendColors <- c("red","hotpink","blue", "steelblue3")
  }else{
    legendNames<- c("SLD Cases","Loess Smoothing")
    legendColors<- c("red","blue")
  }
  legend("topright", legend=legendNames, col=legendColors, lty=1, cex=.75)
  axis(1,
     pretty(SourceDF$Date),labels =format(pretty(SourceDF$Date), "%Y-%m-%d"))
     #pretty(format(SourceDF$Date, "%Y-%m-%d")))
}

SLDGraphics <- function(SiteS,DepTSVec,IndTSVec,DepName,IndName,efficient=FALSE){
  print("Visual Relationship")
  TSPloting(list(DepTSVec,IndTSVec),MergedDF,DepName,IndName,
            FullPlot=FALSE,SubTitle=SiteS)
  TSPloting(list(DepTSVec,IndTSVec),MergedDF,DepName,IndName,
          FullPlot=FALSE,SubTitle=SiteS,FirstDif=TRUE)

  CCFVec <- ccf(IndTSVec,DepTSVec,
               main=paste("CC between",IndName,"and", DepName),
               sub=SiteS)
  OffSet <- which(CCFVec[[1]]==max(CCFVec[[1]]))-21 #Best offset of Straight ccf
  
  
  preWhiteFit <- auto.arima(IndTSVec, seasonal=FALSE,
  stepwise=FALSE, approximation=FALSE) #underlying arima trend of Ind

  IndResid <- IndTSVec - fitted(Arima(IndTSVec, model = preWhiteFit))
  DepResid <- DepTSVec - fitted(Arima(DepTSVec, model = preWhiteFit))
  CCFVecPre <- ccf(IndResid, DepResid,lag.max=22,
               main=paste("prewhiten CC between",IndName,"and", DepName),
               sub=SiteS) #CC removing Arima relationship of Ind
  
  OffSetWhit <- which(CCFVecPre[[1]]==max(CCFVecPre[[1]]))-21#Best offset of PreWhite ccf
  
  if(max(CCFVecPre[[1]])<.15){ #If no prewhite corr is significant then use straight ccf
    print("no signifigent prewhitened relationship")
    OffSetWhit <- OffSet
  }
  
  print(paste("using offset of", OffSetWhit))
  
  TSUnionDF <- ts.intersect(DepTSVec,
                      OGVec = stats::lag(IndTSVec,OffSetWhit))
  
  print("Visual Relationship with offset")
  TSPloting(list(TSUnionDF[,1],TSUnionDF[,2]),MergedDF,DepName,IndName,
            FullPlot=FALSE,SubTitle=SiteS)
  TSPloting(list(TSUnionDF[,1],TSUnionDF[,2]),MergedDF,DepName,IndName,
            FullPlot=FALSE,SubTitle=SiteS,FirstDif=TRUE)
  

  OLM <- lm(TSUnionDF[,1]~TSUnionDF[,2])
  print("Ordinary LM")
  print(summary(OLM))
  ggtsdisplay(residuals(OLM))
  FM <- auto.arima(TSUnionDF[,1],xreg=TSUnionDF[,2])
  #FM <- cochrane.orcutt(OLM,max.iter=1000)
  print("LM with Arima residuals")
  ggtsdisplay(residuals(FM))
  print(summary(FM))
  return(FM)
}
```

```{r Madison Prep, fig.height=3}
FullMadLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),"Madison")

SCPDF <- DFSmoothingFNC(FullCase,SiteS="Madison")%>%
  mutate(Site="Madison")

SCPDF2 <- DFSmoothingFNC(FullCase,PreRoll=TRUE,SiteS="Madison")%>%
  mutate(Site="Madison")

SCPDF3 <- inner_join(SCPDF,SCPDF2,by=c("Date","Site","Cases"),suffix=c("",".PreRolled"))
MergedDF <- inner_join(SCPDF3,FullMadLimsDF, by=c("Date","Site"))

MergedDF$LoessN1 <- DFLoessFNC(MergedDF,SiteS="Madison")

MergedDF <- MergedDF%>%
  select(Date,Site,Cases,Cases2,Cases2.PreRolled,N1,LoessN1,N1Error)

TSDF <- ts(MergedDF,start = 18520)
SLDPreRolledVec <- TSDF[,5]
SLDCaseVec <- TSDF[,4]
CaseVec <- TSDF[,3]
loessN1Vec <- TSDF[,7]
logN1Vec <- log(TSDF[,6])

plot(SLDPreRolledVec)
plot(SLDCaseVec)
```


--------------------------

```{r Mad Full Graphic, include=FALSE}
SLDGraphics("Madison",SLDPreRolledVec,loessN1Vec,"SLD","log(N1)")


#library(TSA)
#arimax(SLDCaseVec,order=c(2,1,0),xreg=loessN1Vec)

#7 day weekly average

#instead do regression model of cases by day of week
#changing seasonality
#is model useful
#SARIMA residuals
#cases method
#color coat axis
#fix all labeling inconsistency
#loess
#add cases and 7 day cases and log(N1) to plot
```

```{r}
#asks Nathan for fuller case data
#SLD to pure N1
#logN1 SSD  comp give stats to optimize
#seasonal effect?
#waldtest(SLDModel[,1],SLDModel[,2])

#Pre whiting - auto correlation removing
#
#First diff acts as derivative for perfect smooth
#First diff is hard to interpret with noisy data
#goal is not perfect correlation: goal is to have principled analysis that helps 
#explain what we see to test different changes
#
#is we get something that works great for madison. Nathan will finish


#Rolling correlation -- CCF
#Pre whiting - auto correlation removing
#normalizing by PMMoV - worked at some points but noise in PMMoV hurt
#loess smoothing on PMMoV might help with that
#revisit norm
#revisit N1 N2
#library(lmtest)
```

```{r}

# 
# SLDModelPEight <- SLDGraphics("MMSD-P18",Diffs=1)
# 
# intersect(unique(LIMSFullDF$Site),unique(FullCase$Site))

#great: Madison, P11, P7
#ok: P8
#bad: p18
```


```{r}
# library(tseries)
# #library(dLagM)
# 
# #ts.plot(diff(aba[,1],2),stats::lag(150*diff(aba[,2],2),12),col=c("red","blue"))
# #adf.test(diff(aba[,1],2))
# 
# rolCorPlot(aba[,1],aba[,2],width=7)
# library(tidyquant)
```

```{r}
# library("portes")
# library(TSA)
# SLDTS <- SLDModel[,6]
# N1 <- log(SLDModel[,8])
# LoessN1 <- log(SLDModel[,15])
# auto.arima(diff(LoessN1, seasonal=FALSE,
#   stepwise=FALSE, approximation=FALSE))
# fit2 <- Arima(N1, order=c(1,1,1))
# 
# x <- N1 - fitted(Arima(N1, model = fit2))
# y <- SLDTS - fitted(Arima(SLDTS, model = fit2))
# ccf(x, y)
# 
# ggtsdisplay(x)
# ggtsdisplay(y)
# #prewhiten(N1, SLDTS, x.model = mod1)
# 
# 
# 
# XReg <- do.call(ts.intersect,lapply(1:14,stats::lag,x=LoessN1))
# colnames(XReg) <- 1:14
# MainDriver <- ts.intersect(XReg,SLDTS)
# 
# regmodel=lm(diff(SLDTS)~diff(XReg.14),data=MainDriver)
# summary(regmodel)
# ggtsdisplay(diff(MainDriver[,14]))
# ggtsdisplay(diff(MainDriver[,15]))
# ggtsdisplay(residuals(regmodel))
# 
# ar1res = Arima(residuals(regmodel), order=c(1,0,0))
# xl = ts.intersect(MainDriver[,14], stats::lag(MainDriver[,14],-1))
# xnew=xl[,1] - 0.6488*xl[,2]
# yl = ts.intersect(MainDriver[,15],stats::lag(MainDriver[,15],-1))
# ynew=yl[,1]-0.6488*yl[,2]
#  
# adjustreg = lm(ynew~xnew) # Adjustment regression
# summary(adjustreg)
# ggtsdisplay(residuals(adjustreg))
```

```{r}
# library(forecast)
# library(slider)
# 
# mod1 <- Arima(LoessN1, order=c(4,2,0))
# x <- LoessN1 - fitted(Arima(LoessN1, model = mod1))
# y <- SLDTS - fitted(Arima(SLDTS, model = mod1))
# ccf(x, y)
# ccf(LoessN1,SLDTS)
# ggtsdisplay(x)
# ggtsdisplay(y)
# mod1 <- Arima(LoessN1, order=c(4,2,0))
# 
# 
# ggtsdisplay(diff(LoessN1,differences=2))
# ggtsdisplay(diff(SLDTS,differences=2))
# ccf(diff(LoessN1,differences=2),diff(SLDTS,differences=2))
# 
# 
# 
# XReg <- do.call(ts.intersect,lapply(-10:10,stats::lag,x=LoessN1))
# colnames(XReg) <- -10:10
# MainDriver <- ts.intersect(XReg,SLDTS)
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,1:21]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,1:11]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,11:21]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,15:18]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,16:18]))
# 
# (fit <- auto.arima(MainDriver[,22], xreg=MainDriver[,15:18]))
# summary(fit)


#library(TSA)
#arimax
```

```{r 6 part plot}
#(SourceDF$N1Error)
TSPloting2 <- function(PlotingTS,SourceDF,SubTitle,SLD=TRUE){
  if(SLD){
    Shade <- 0.5
    Thickness <- 1
  }else{
    Shade <-1
    Thickness <- 2
  }
  RangeCases <- range(PlotingTS[[3]],na.rm=TRUE)
  RangeN1 <- range(SourceDF$N1,na.rm=TRUE)
  plot.new()
  par(mar = c(8, 4, 4, 4) + 0.1)
  plot(1, type="n", xlab=SubTitle, ylab="", axes = FALSE,
       xlim=range(SourceDF$Date), ylim=RangeN1,log="y")
  rect(SourceDF$Date-.5,
       SourceDF$N1-SourceDF$N1Error,
       SourceDF$Date+.5,
       SourceDF$N1+SourceDF$N1Error,
      col  = rgb(0, 0, 1, alpha=0.25),
      border  = NA,
      xlab = "",
      ylab = "",
      xaxt = "n")
  par(new = TRUE)
  barplot(as.numeric(PlotingTS[[3]]),
          col  = rgb(1, 0, 0, alpha=0.1),
          xlab = "",
          ylab = "",
          xaxt = "n",
          border = NA,
          ylim = RangeCases,
          axes = FALSE)
  par(new = TRUE)
  
  plot.ts(rollmean(PlotingTS[[3]], 7,align="right",fill = NA),
         col = rgb(1, 0, 0, alpha=Shade),
          ylim = RangeCases,
   axes = FALSE,
   lwd=Thickness,
   xlab = "",
   ylab = "",
   xaxt = "n")
  axis(4, pretty(RangeCases),col.axis = "red",cex.axis=.75)
  
  RangeDates <- range(SourceDF$Date)
  ticks <- seq(RangeDates[1],RangeDates[2], by = "month")
  axis(1,
     ticks,
     labels = FALSE,
     cex.axis=.5)
  text(cex=.75, x=ticks-15, y=-115, format(ticks,"%b %Y"),
       xpd=TRUE, srt=30)
  
  par(new = TRUE)
  plot.ts(exp(PlotingTS[[2]]),
            col = "blue",
       ylim = RangeN1,
       axes = FALSE,
       xlab = "",
       ylab = "",
       log="y",
       lwd=2,
       xaxt = "n")
  axis(2,col.axis = "blue",cex.axis=.75)
  
  legendNames <- c("7 day MA Cases","loess smoothing with span=.125")
  legendColors <- c(rgb(1, 0, 0, alpha=Shade),"blue")
  if(SLD){
    legendNames <- c("Shedding lag distribution",legendNames)
  legendColors <- c("red",legendColors)
    
    par(new = TRUE)
    plot.ts(PlotingTS[[1]],
          ylim = RangeCases,
          col = "red",
          lwd=2,
      axes = FALSE,
     xlab = "", ylab = "",xaxt = "n")
  }
  mtext("Cases", side = 4, line = 2, col = "red",cex=.75)
  mtext("N1 (GC/L)", side = 2, line = 2, col = "blue",cex=.75)


  legend("topright", legend=legendNames, col=legendColors, lty=1, cex=.5)
  
}

TSPloting2(list(SLDPreRolledVec,loessN1Vec,CaseVec),MergedDF,
            SubTitle="Madison",SLD=FALSE)
TSPloting2(list(SLDPreRolledVec,loessN1Vec,CaseVec),MergedDF,
            SubTitle="Madison")



```

-----------------------------------------------


```{r Dorms}
Site="UW-LakeShore"
#UW-Sellery
#UW-LakeShore
FullLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),Site)
SmoothCasePlotDF <- DFSmoothingFNC(FullCase,SiteS=Site,
                                   Weights=c(rep(0,10),
                              dgamma(1:21,
                              scale=scale,
                              shape=shape)[11:21]))

FullLimsDF$LoessN1 <- DFLoessFNC(FullLimsDF,SiteS=Site)

MergedDF <- inner_join(SmoothCasePlotDF,FullLimsDF,
                       by=c("Date","Site"))

MergedDF <- MergedDF%>%
  select(Date,Site,Cases,Cases2,N1,LoessN1,N1Error)

TSDF <- ts(MergedDF,start = 18520)
SLDCaseVec <- TSDF[,4]
CaseVec <- TSDF[,3]
loessN1Vec <- TSDF[,6]
logN1Vec <- log(TSDF[,5])

SLDModelMad <- SLDGraphics(Site,SLDCaseVec,loessN1Vec,"SLD","log(N1)")

TSPloting2(list(SLDCaseVec,loessN1Vec,CaseVec),MergedDF,
            SubTitle=Site,SLD=TRUE)
```
-----------------------------------------

```{r Sell}
DormGraphics <- function(Site,InDepth=FALSE,Short=TRUE){
  FullLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),Site)
  SCPDF <- DFSmoothingFNC(FullCase,SiteS=Site,
                                Weights=c(rep(0,10),
                                dgamma(1:21,
                                scale=scale,
                                shape=shape)[11:21]))
  
  SCPDF2 <- DFSmoothingFNC(FullCase,PreRoll=TRUE,SiteS=Site,
                                Weights=c(rep(0,10),
                                dgamma(1:21,
                                scale=scale,
                                shape=shape)[11:21]))%>%
    mutate(Site=Site)
  
  SCPDF3 <- inner_join(SCPDF,SCPDF2,by=c("Date","Site","Cases"),suffix=c("",".PreRolled"))
  MergedDF <- inner_join(SCPDF3,FullLimsDF, by=c("Date","Site"))
  
  
  MergedDF$LoessN1 <- DFLoessFNC(MergedDF,SiteS=Site)
  
  MergedDF <- MergedDF%>%
    select(Date,Site,Cases,Cases2,Cases2.PreRolled,N1,LoessN1,N1Error)
  
  TSDF <- ts(MergedDF,start = 18520)
  SLDPreRolledVec <- TSDF[,5]
  SLDCaseVec <- TSDF[,4]
  CaseVec <- TSDF[,3]
  loessN1Vec <- TSDF[,7]
  logN1Vec <- log(TSDF[,6])
  if(InDepth){
    SLDModelMad <- SLDGraphics(Site,SLDPreRolledVec,loessN1Vec,"SLD","log(N1)")
  }
  if(Short){
    TSPloting2(list(SLDPreRolledVec,loessN1Vec,CaseVec),MergedDF,
                SubTitle=Site,SLD=TRUE)
  }
  return(TSDF)
}
# plot(SLDPreRolledVec)
# plot(SLDCaseVec)
DormGraphics("Spring UW-Sellery")
ListDiscard <- lapply(c("Spring UW-Sellery","Fall UW-Sellery",
         "Spring UW-LakeShore","Fall UW-LakeShore"),DormGraphics)
#Fall UW-Sellery
#UW-LakeShore
```



----------------------------------------------------------------


```{r}
missing_codes <- MissingCode()
LIMSFullDF2 <- read_excel(LIMSFN,
                                  na  =  missing_codes,
                                  col_types = c(rep("guess",48),"text",rep("guess",12)))%>%
  rename(Site=wwtp_name,
         collected=sample_collect_date,
         tested=test_result_date,
         N1=n1_sars_cov2_conc)%>%
  mutate(collected=mdy(collected),
         tested=as.Date(as.POSIXct(tested,format='%m/%d/%Y ')),
         N1=as.numeric(N1),
         TimeDiff=tested-collected)


#sample_collect_date
#sample_collect_time
#test_result_date
#unformatted_collectdate

LIMSFullDF2%>%
  filter(Site=="Madison Metro")%>%
  ggplot()+
  aes(y=N1)+
  geom_point(aes(x=collected,color="col"))+
  geom_point(aes(x=tested,color="Tested"))+
  scale_y_log10()
  
LIMSFullDF2%>%
  filter(Site=="Madison Metro")%>%
  ggplot()+
  aes(y=N1)+
  geom_point(aes(x=TimeDiff,color="col"))+
  #geom_point(aes(x=tested,color="Tested"))+
  scale_y_log10()

LIMSFullDF2%>%
  ggplot()+
  aes(y=TimeDiff)+
  geom_point(aes(x=collected))

LIMSFullDF2%>%
  #filter(TimeDiff<50)%>%
  ggplot()+
  aes(y=TimeDiff)+
  geom_point(aes(x=collected))+
  geom_vline(aes(xintercept =mdy("12-15-2020")))+
  geom_hline(aes(yintercept =80))


LIMSFullDF2%>%
  #filter(TimeDiff<50)%>%
  mutate(Time=ifelse(collected<mdy("12-15-2020"),"Pre2021","2021"))%>%
  group_by(Time)%>%
  summarise(mean=mean(log(N1),na.rm=TRUE),
            var=var(log(N1),na.rm=TRUE),
            meanDif=mean(TimeDiff,na.rm=TRUE),
            varDif=var(TimeDiff,na.rm=TRUE))



Aba=LIMSFullDF2%>%
  mutate(Time=ifelse(collected<mdy("12-15-2020"),"Pre2021","2021"))
summary(aov(N1~Time,data=Aba))

DecayRate=-0.041

LIMSFullDF2%>%
  filter(Site=="Madison Metro")%>%
  mutate(N1P=N1*exp(1)^(.041*as.numeric(TimeDiff)))%>%
  mutate(Outliers=ifelse(TimeDiff>12,"Long delay","Normal delay"))%>%
  ggplot()+
  aes(x=collected,color=Outliers)+
  geom_point(aes(y=N1P))+
  scale_y_log10()
  #geom_point(aes(y=N1P))
```


