---
title: "SheddingLagDistribution"
author: "Marlin"
date: "7/22/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r set up markdown settings, echo=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)

```

```{r Start enviroment, message=FALSE, warning=FALSE}
library(ggpubr)
library(dplyr)
library(forecast)
library(lmtest)
library(lubridate)
library(limma)
library(zoo)

#Data Files and prep work
source("../../Scripts/GenPlotMaking.R")
source("../../Scripts/WasteWaterDataProccess.R")
source("../../Scripts/CassesDataProccess.R")
source("../../Scripts/HelperFunctions.R")
```


```{r DF Set Up}
PathStarter="Z:/"

LatMMSDFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/MMSD_Cases.csv")
LIMSFN <- paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/WATERMICRO_WW_COVID-2021-06-30 17 40.xlsx")

HFGCasesFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/HighFreq_CaseData_2021-05-07.csv")


LatCaseDF <- CovidDataPARSER(MMSDFN = LatMMSDFN)%>%
  filter(!is.na(Site))%>%
  select(Date,Site,Cases,Tests,Per_pos)

HFGCaseDF <- HFGCasesPARSER(FN = HFGCasesFN)%>%
  filter(!is.na(Site))%>%
  mutate(Tests=NA,Per_pos=NA)%>%
  select(Date,Site,Cases=ReportedCases,Tests,Per_pos)%>%
  mutate(Cases = ifelse(Cases==-999,2.5,Cases))%>%
  filter(Site!="Madison")

FullCase <- rbind(HFGCaseDF,LatCaseDF)

LIMSFullDF <- LIMSDataPARSER(LIMSFN)%>%
  select(Date,Site, BCoV, N1,N1Error,N2, N2Error,PMMoV,Pop,FlowRate)

CaseSum=FullCase%>%
  filter(!is.na(Cases))%>%
  group_by(Site)%>%
  summarise(NCase=n())

N1Sum=LIMSFullDF%>%
  filter(!is.na(N1))%>%
  group_by(Site)%>%
  summarise(NN1=n())

DataComp <- inner_join(CaseSum,N1Sum,by=c("Site"))%>%
  mutate(Dif=NCase-NN1,min=ifelse(NCase<NN1,NCase,NN1))
LowCaseDataPoints <- DataComp%>%
  filter(Dif<0)
```


```{r CaseSmoothing}
#return( RollPerPos(CaseDF,"Cases","Tests",Facet="Site"))
library(limma)
DataPrep <- function(DF,SiteS=NA,keep=c()){
  if(!is.na(SiteS)){
    FilteredVec1 <- filter(DF,Site==SiteS)
  }else{
    FilteredVec1 <- DF
  }
  
  FullDayDF <- data.frame(Date=seq(min(FilteredVec1$Date),
                                   max(FilteredVec1$Date),1))
  ReadyDF <- full_join(FullDayDF,FilteredVec1, by = c("Date"))%>%
    fill(one_of(keep), .direction = "down")%>%
    mutate(Site=SiteS)%>%
    select(Date,one_of(keep),Site,)
  return(ReadyDF)
}


DFSmoothingFNC <- function(CaseDF,SiteS){
  #5.028338
  scale =5.028338
  #2.332779
  shape =2.332779
  FullDayDF <- DataPrep(CaseDF,"Cases",SiteS=SiteS)%>%
    group_by(Site)%>%
    mutate(Cases2 = c(rep(NA,20),
                    rollapply(Cases,width=21,FUN=weighted.mean,
                          w=dgamma(1:21,scale =scale,shape =shape),
                          na.rm = TRUE)))
}

DFLoessFNC <- function(N1DF,SiteS){

    ReadyDF <- DataPrep(N1DF,keep=c("N1"),SiteS=SiteS)
    
    loessFit(y=log(ReadyDF$N1),
             x=ReadyDF$Date,
             span=.125,
             min.weight=0,
             max.weight=1e5,
             iterations=20)$fitted
}

  #5.028338
scale =5.028338
  #2.332779
shape =2.332779
  
plot(dgamma(1:21,scale =scale,shape =shape), 
            main="Gamma Distribution with mean = 11.73 days and SD = 7.68",
            ylab = "Weight",
            xlab = "Lag")

```


```{R TSPliting}

#library(smooth)
#sma(MergedDF[,8], h=7)

# fit = Arima(CasesTSVec, xreg=loessPred, order=c(2,1,0))
# 
# cbind("Regression Errors" = residuals(fit, type="regression"),
#       "ARIMA errors" = residuals(fit, type="innovation")) %>%
#   autoplot(facets=TRUE)
# checkresiduals(fit)
#
 

#alt y axis
#x axis labled as date
#control color so they are not so light
#2)Show original data as bar graph?
#Make it clear its Madison/Title that explains
#few people have done SLD
```

```{r Formal Work, include=FALSE}
# IndependentVec <- diff(loessPred)
# DependentVec <- diff(CasesTSVec)
# 
# ccfvalues2  <-  ccf(IndependentVec,DependentVec,type = c("correlation"),na.action = na.pass)
# ccfvalues2  <-  ccf(loessPred,CasesTSVec,type = c("correlation"),na.action = na.pass)
# 
# alldata1 <- ts.union(Pred = diff(CasesTSVec),N1Norm = diff(loessPred),
#                          N1TSVec,
#                          N1A=stats::lag(diff(loessPred),1),
#                          N1B=stats::lag(diff(loessPred),10),
#                          N1C=stats::lag(diff(loessPred)))
# 
# 
# tryit1a  <- lm(Pred~N1B, data = alldata1)
# 
# summary(tryit1a)
# #plot(tryit1a)
# acf(residuals(tryit1a))
```

```{r}
#Do for non interceptor data
 
#Transformation to stabilize scale
 
 
#1)Make overlay plot function
#a)normal comp
#b)first difference
#c)P8 version
#compare smooth vs Smooth  ccf
#show all smooth Unsmooth combos
#look for best gamma
 
 
#CCF
#broke it into 2 parts
#CCF of SLD vs raw N1
 
#ccf(CasesTSVec,)
 
#some pipeline to optimize
#What did the original paper do? are we doing the same thing
#case reported at day A
#What we want: when person A became infected
#What we expect: SLD leads Cases
#infected a week and a half ago - some people are still shedding
#if looking at cases you have 3 gammas 
#Cases ~ 2 gamma ~ infected ~ 1 gamma ~ still shedding 
 
#1) Focus on 2 or 3 plots give very clear heuristic picture. in form that does not need words
 
#2)CCF that gives metric behind heuristic
 
#3)
 #FullCase
```
 
 
```{r Ploting Fnc} 
#library(dynlm)

IsFull <- function(DF){
  return(length(DF$Date)==max(DF$Date)-min(DF$Date)+1)
}

TSPloting <- function(PlotingTS,SourceDF,DepName,IndName,FullPlot=TRUE,SubTitle=NA,FirstDif=FALSE){
  if(FirstDif){
    PlotingTS[[2]] <- diff(PlotingTS[[2]])
    PlotingTS[[1]] <- diff(PlotingTS[[1]])
    Lab <- paste("First Diffrence of", DepName, "and", IndName)
  }else{
    Lab <- paste("Visual relationship of", DepName, "and", IndName)
  }
  plot.new()
  par(mar = c(5, 4, 4, 4) + 0.3)           

  if(FullPlot){
    plot.ts(rollmean(exp(PlotingTS[[4]]), 7,align="right",fill = NA),
            col = "steelblue3", 
            axes = FALSE, 
            xlab = "", 
            ylab = "",
            xaxt = "n",
            log="y")
    
    axis(side = 4, col.axis="blue")
    
    par(new = TRUE)  
    plot.ts(rollmean(PlotingTS[[3]], 7,align="right",fill = NA),
            col = "hotpink",        
       axes = FALSE, xlab = "", ylab = "",xaxt = "n")
    
    par(new = TRUE)  
    plot.ts(exp(PlotingTS[[2]]),
            col = "blue",        
       axes = FALSE, 
       xlab = "", 
       ylab = "",
       log = 'y',
       xaxt = "n")
  }else{
    plot.ts(exp(PlotingTS[[2]]), 
          col = "blue", 
          axes = FALSE,
          main=Lab,
          ylab="",
          sub=SubTitle,
          log = 'y',
          xaxt = "n")
    axis(side = 4, col.axis="blue")
  }

  par(new = TRUE)                           
  plot.ts(PlotingTS[[1]], col = "red",        
     axes = FALSE, xlab = "", ylab = "",xaxt = "n")

  axis(side = 2, at = pretty(range(PlotingTS[[1]])),col.axis="red")
  mtext("Cases", side = 2, line = 3, col = "red")
  mtext("N1 (GC/L)", side = 4, line = 3, col = "blue")
  if(FullPlot){
    legendNames <- c("SLD Cases","7 MA Cases","Loess Smoothing","7 MA N1")
    legendColors <- c("red","hotpink","blue", "steelblue3")
  }else{
    legendNames<- c("SLD Cases","Loess Smoothing")
    legendColors<- c("red","blue")
  }
  legend("topright", legend=legendNames, col=legendColors, lty=1, cex=.75)
  axis(1,
     pretty(SourceDF$Date),labels =format(pretty(SourceDF$Date), "%Y-%m-%d"))
     #pretty(format(SourceDF$Date, "%Y-%m-%d")))
}

SLDGraphics <- function(SiteS,DepTSVec,IndTSVec,DepName,IndName,efficient=FALSE){
  print("Visual Relationship")
  TSPloting(list(DepTSVec,IndTSVec),MergedDF,DepName,IndName,
            FullPlot=FALSE,SubTitle=SiteS)
  TSPloting(list(DepTSVec,IndTSVec),MergedDF,DepName,IndName,
          FullPlot=FALSE,SubTitle=SiteS,FirstDif=TRUE)

  CCFVec <- ccf(IndTSVec,DepTSVec,
               main=paste("CC between",IndName,"and", DepName),
               sub=SiteS)
  OffSet <- which(CCFVec[[1]]==max(CCFVec[[1]]))-21 #Best offset of Straight ccf
  
  
  preWhiteFit <- auto.arima(IndTSVec, seasonal=FALSE,
  stepwise=FALSE, approximation=FALSE) #underlying arima trend of Ind

  IndResid <- IndTSVec - fitted(Arima(IndTSVec, model = preWhiteFit))
  DepResid <- DepTSVec - fitted(Arima(DepTSVec, model = preWhiteFit))
  CCFVecPre <- ccf(IndResid, DepResid,lag.max=22,
               main=paste("prewhiten CC between",IndName,"and", DepName),
               sub=SiteS) #CC removing Arima relationship of Ind
  
  OffSetWhit <- which(CCFVecPre[[1]]==max(CCFVecPre[[1]]))-21#Best offset of PreWhite ccf
  
  if(max(CCFVecPre[[1]])<.15){ #If no prewhite corr is significant then use straight ccf
    print("no signifigent prewhitened relationship")
    OffSetWhit <- OffSet
  }
  
  print(paste("using offset of", OffSetWhit))
  
  TSUnionDF <- ts.intersect(DepTSVec,
                      OGVec = stats::lag(IndTSVec,OffSetWhit))
  
  print("Visual Relationship with offset")
  TSPloting(list(TSUnionDF[,1],TSUnionDF[,2]),MergedDF,DepName,IndName,
            FullPlot=FALSE,SubTitle=SiteS)
  TSPloting(list(TSUnionDF[,1],TSUnionDF[,2]),MergedDF,DepName,IndName,
            FullPlot=FALSE,SubTitle=SiteS,FirstDif=TRUE)
  

  OLM <- lm(TSUnionDF[,1]~TSUnionDF[,2])
  print("Ordinary LM")
  print(summary(OLM))
  ggtsdisplay(residuals(OLM))
  FM <- auto.arima(TSUnionDF[,1],xreg=TSUnionDF[,2])
  #FM <- cochrane.orcutt(OLM,max.iter=1000)
  print("LM with Arima residuals")
  ggtsdisplay(residuals(FM))
  print(summary(FM))
  return(FM)
}
```


```{r Madison}
FullMadLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),"Madison")
SmoothCasePlotDF <- DFSmoothingFNC(FullCase,SiteS="Madison")%>%
  mutate(Site="Madison")#%>%
    #filter(!is.na(Cases2))

MergedDF <- inner_join(SmoothCasePlotDF,FullMadLimsDF, by=c("Date","Site"))
MergedDF$LoessN1 <- DFLoessFNC(MergedDF,SiteS="Madison")
MergedDF <- MergedDF%>%
  select(Date,Site,Cases,Cases2,N1,LoessN1,N1Error)

TSDF <- ts(MergedDF,start = 18520)
SLDCaseVec <- TSDF[,4]
CaseVec <- TSDF[,3]
loessN1Vec <- TSDF[,6]
logN1Vec <- log(TSDF[,5])

SLDModelMad <- SLDGraphics("Madison",SLDCaseVec,loessN1Vec,"SLD","log(N1)")


#library(TSA)
#arimax(SLDCaseVec,order=c(2,1,0),xreg=loessN1Vec)

#7 day weekly average

#instead do regression model of cases by day of week
#changing seasonality
#is model useful
#SARIMA residuals
#cases method
#color coat axis
#fix all labeling inconsistency
#loess
#add cases and 7 day cases and log(N1) to plot
```

```{r}
#asks Nathan for fuller case data
#SLD to pure N1
#logN1 SSD  comp give stats to optimize
#seasonal effect?
#waldtest(SLDModel[,1],SLDModel[,2])

#Pre whiting - auto correlation removing
#
#First diff acts as derivative for perfect smooth
#First diff is hard to interpret with noisy data
#goal is not perfect correlation: goal is to have principled analysis that helps 
#explain what we see to test different changes
#
#is we get something that works great for madison. Nathan will finish


#Rolling correlation -- CCF
#Pre whiting - auto correlation removing
#normalizing by PMMoV - worked at some points but noise in PMMoV hurt
#loess smoothing on PMMoV might help with that
#revisit norm
#revisit N1 N2
#library(lmtest)
```

```{r}

# 
# SLDModelPEight <- SLDGraphics("MMSD-P18",Diffs=1)
# 
# intersect(unique(LIMSFullDF$Site),unique(FullCase$Site))

#great: Madison, P11, P7
#ok: P8
#bad: p18
```


```{r}
# library(tseries)
# #library(dLagM)
# 
# #ts.plot(diff(aba[,1],2),stats::lag(150*diff(aba[,2],2),12),col=c("red","blue"))
# #adf.test(diff(aba[,1],2))
# 
# rolCorPlot(aba[,1],aba[,2],width=7)
# library(tidyquant)
```

```{r}
# library("portes")
# library(TSA)
# SLDTS <- SLDModel[,6]
# N1 <- log(SLDModel[,8])
# LoessN1 <- log(SLDModel[,15])
# auto.arima(diff(LoessN1, seasonal=FALSE,
#   stepwise=FALSE, approximation=FALSE))
# fit2 <- Arima(N1, order=c(1,1,1))
# 
# x <- N1 - fitted(Arima(N1, model = fit2))
# y <- SLDTS - fitted(Arima(SLDTS, model = fit2))
# ccf(x, y)
# 
# ggtsdisplay(x)
# ggtsdisplay(y)
# #prewhiten(N1, SLDTS, x.model = mod1)
# 
# 
# 
# XReg <- do.call(ts.intersect,lapply(1:14,stats::lag,x=LoessN1))
# colnames(XReg) <- 1:14
# MainDriver <- ts.intersect(XReg,SLDTS)
# 
# regmodel=lm(diff(SLDTS)~diff(XReg.14),data=MainDriver)
# summary(regmodel)
# ggtsdisplay(diff(MainDriver[,14]))
# ggtsdisplay(diff(MainDriver[,15]))
# ggtsdisplay(residuals(regmodel))
# 
# ar1res = Arima(residuals(regmodel), order=c(1,0,0))
# xl = ts.intersect(MainDriver[,14], stats::lag(MainDriver[,14],-1))
# xnew=xl[,1] - 0.6488*xl[,2]
# yl = ts.intersect(MainDriver[,15],stats::lag(MainDriver[,15],-1))
# ynew=yl[,1]-0.6488*yl[,2]
#  
# adjustreg = lm(ynew~xnew) # Adjustment regression
# summary(adjustreg)
# ggtsdisplay(residuals(adjustreg))
```


```{r}
# library(forecast)
# library(slider)
# 
# mod1 <- Arima(LoessN1, order=c(4,2,0))
# x <- LoessN1 - fitted(Arima(LoessN1, model = mod1))
# y <- SLDTS - fitted(Arima(SLDTS, model = mod1))
# ccf(x, y)
# ccf(LoessN1,SLDTS)
# ggtsdisplay(x)
# ggtsdisplay(y)
# mod1 <- Arima(LoessN1, order=c(4,2,0))
# 
# 
# ggtsdisplay(diff(LoessN1,differences=2))
# ggtsdisplay(diff(SLDTS,differences=2))
# ccf(diff(LoessN1,differences=2),diff(SLDTS,differences=2))
# 
# 
# 
# XReg <- do.call(ts.intersect,lapply(-10:10,stats::lag,x=LoessN1))
# colnames(XReg) <- -10:10
# MainDriver <- ts.intersect(XReg,SLDTS)
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,1:21]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,1:11]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,11:21]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,15:18]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,16:18]))
# 
# (fit <- auto.arima(MainDriver[,22], xreg=MainDriver[,15:18]))
# summary(fit)


#library(TSA)
#arimax
```

```{r 6 part plot}
#(SourceDF$N1Error)
TSPloting <- function(PlotingTS,SourceDF,SubTitle){
  RangeCases <- range(PlotingTS[[3]],na.rm=TRUE)
  RangeN1 <- range(SourceDF$N1,na.rm=TRUE)
  plot.new()
  par(mar = c(5, 4, 4, 4) + 0.3)
  plot(1, type="n", xlab=SubTitle, ylab="", axes = FALSE,
       xlim=range(SourceDF$Date), ylim=RangeN1,log="y")
  rect(SourceDF$Date-.5,
       SourceDF$N1-SourceDF$N1Error,
       SourceDF$Date+.5,
       SourceDF$N1+SourceDF$N1Error,
      col  = rgb(0, 0, 1, alpha=0.05),
      border  = NA,
      xlab = "",
      ylab = "",
      xaxt = "n")
  par(new = TRUE)
  barplot(as.numeric(PlotingTS[[3]]),
          col  = rgb(1, 0, 0, alpha=0.05),
          xlab = "",
          ylab = "",
          xaxt = "n",
          border = NA,
          ylim = RangeCases,
          axes = FALSE)
  par(new = TRUE)
  plot.ts(rollmean(exp(PlotingTS[[4]]), 7,align="right",fill = NA),
          col = rgb(0, 0, 1, alpha=0.3),
          xlab = "",
          ylab = "",
          xaxt = "n",
          axes = FALSE,
          ylim = RangeN1,
          log="y")
  axis(4,col.axis = "blue")
  par(new = TRUE)
  plot.ts(rollmean(PlotingTS[[3]], 7,align="right",fill = NA),
         col = rgb(1, 0, 0, alpha=0.3),
          ylim = RangeCases,
   axes = FALSE,
   xlab = "",
   ylab = "",
   xaxt = "n")

  par(new = TRUE)
  plot.ts(exp(PlotingTS[[2]]),
            col = "blue",
       ylim = RangeN1,
       axes = FALSE,
       xlab = "",
       ylab = "",
       log="y",
       xaxt = "n")

  par(new = TRUE)
  plot.ts(PlotingTS[[1]],
          ylim = RangeCases,
          col = "red",
      axes = FALSE,
     xlab = "", ylab = "",xaxt = "n")
  axis(2, pretty(RangeCases),col.axis = "red")
  mtext("Cases", side = 2, line = 3, col = "red")
  mtext("N1 (GC/L)", side = 4, line = 3, col = "blue")

  legendNames <- c("SLD Cases","7 MA Cases","Loess Smoothing","7 MA N1")
  legendColors <- c("red","hotpink","blue", "steelblue3")

  legend("topright", legend=legendNames, col=legendColors, lty=1, cex=.6)
  axis(1,
     pretty(SourceDF$Date),labels =format(pretty(SourceDF$Date), "%Y-%m-%d"))
}


TSPloting(list(SLDCaseVec,loessN1Vec,CaseVec,logN1Vec),MergedDF,
            SubTitle="Madison")


```

