---
title: "SheddingLagDistribution"
author: "Marlin"
date: "7/22/2021"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r set up markdown settings, echo=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)

```

```{r Start enviroment, message=FALSE, warning=FALSE}
library(ggpubr)
library(dplyr)
library(forecast)
library(lmtest)
library(lubridate)
library(limma)
library(zoo)

#Data Files and prep work
source("../../Scripts/GenPlotMaking.R")
source("../../Scripts/WasteWaterDataProccess.R")
source("../../Scripts/CassesDataProccess.R")
source("../../Scripts/HelperFunctions.R")

```

```{r DF Set Up}
PathStarter="Z:/"

LatMMSDFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/MMSD_Cases.csv")
LatSpringDormFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/SpringSemester_CasesByDorm.TSV")
LatFallDormFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/FallSemester_CasesByDorm.TSV")

LIMSFN <- paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/WATERMICRO_WW_COVID-2021-06-30 17 40.xlsx")

HFGCasesFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/HighFreq_CaseData_2021-05-07.csv")


LatCaseDF <- CovidDataPARSER(LatSpringDormFN,LatFallDormFN,MMSDFN = LatMMSDFN)%>%
  filter(!is.na(Site))%>%
  select(Date,Site,Cases,Tests,Per_pos)

HFGCaseDF <- HFGCasesPARSER(FN = HFGCasesFN)%>%
  filter(!is.na(Site))%>%
  mutate(Tests=NA,Per_pos=NA)%>%
  select(Date,Site,Cases=ReportedCases,Tests,Per_pos)%>%
  mutate(Cases = ifelse(Cases==-999,2.5,Cases))%>%
  filter(Site!="Madison")

FullCase <- rbind(HFGCaseDF,LatCaseDF)

LIMSFullDF <- LIMSDataPARSER(LIMSFN)%>%
  select(Date,Site, BCoV, N1,N1Error,N2, N2Error,PMMoV,Pop,FlowRate)

CaseSum=FullCase%>%
  filter(!is.na(Cases))%>%
  group_by(Site)%>%
  summarise(NCase=n())

N1Sum=LIMSFullDF%>%
  filter(!is.na(N1))%>%
  group_by(Site)%>%
  summarise(NN1=n())

DataComp <- inner_join(CaseSum,N1Sum,by=c("Site"))%>%
  mutate(Dif=NCase-NN1,min=ifelse(NCase<NN1,NCase,NN1))
LowCaseDataPoints <- DataComp%>%
  filter(Dif<0)

```


```{r CaseSmoothing, include=FALSE}
#return( RollPerPos(CaseDF,"Cases","Tests",Facet="Site"))
library(limma)





  #5.028338
scale =5.028338
  #2.332779
shape =2.332779
  
plot(dgamma(1:21,scale =scale,shape =shape), 
            main="Gamma Distribution with mean = 11.73 days and SD = 7.68",
            ylab = "Weight",
            xlab = "Lag")


plot(c(rep(0,10),dgamma(1:21,scale =scale,shape =shape)[11:21]), 
            main="Gamma Distribution with mean = 11.73 days and SD = 7.68",
            ylab = "Weight",
            xlab = "Lag")


```


```{R TSPliting}

#library(smooth)
#sma(MergedDF[,8], h=7)

# fit = Arima(CasesTSVec, xreg=loessPred, order=c(2,1,0))
# 
# cbind("Regression Errors" = residuals(fit, type="regression"),
#       "ARIMA errors" = residuals(fit, type="innovation")) %>%
#   autoplot(facets=TRUE)
# checkresiduals(fit)
#
 

#alt y axis
#x axis labled as date
#control color so they are not so light
#2)Show original data as bar graph?
#Make it clear its Madison/Title that explains
#few people have done SLD
```

```{r Formal Work, include=FALSE}
# IndependentVec <- diff(loessPred)
# DependentVec <- diff(CasesTSVec)
# 
# ccfvalues2  <-  ccf(IndependentVec,DependentVec,type = c("correlation"),na.action = na.pass)
# ccfvalues2  <-  ccf(loessPred,CasesTSVec,type = c("correlation"),na.action = na.pass)
# 
# alldata1 <- ts.union(Pred = diff(CasesTSVec),N1Norm = diff(loessPred),
#                          N1TSVec,
#                          N1A=stats::lag(diff(loessPred),1),
#                          N1B=stats::lag(diff(loessPred),10),
#                          N1C=stats::lag(diff(loessPred)))
# 
# 
# tryit1a  <- lm(Pred~N1B, data = alldata1)
# 
# summary(tryit1a)
# #plot(tryit1a)
# acf(residuals(tryit1a))
```

```{r}
#Do for non interceptor data
 
#Transformation to stabilize scale
 
 
#1)Make overlay plot function
#a)normal comp
#b)first difference
#c)P8 version
#compare smooth vs Smooth  ccf
#show all smooth Unsmooth combos
#look for best gamma
 
 
#CCF
#broke it into 2 parts
#CCF of SLD vs raw N1
 
#ccf(CasesTSVec,)
 
#some pipeline to optimize
#What did the original paper do? are we doing the same thing
#case reported at day A
#What we want: when person A became infected
#What we expect: SLD leads Cases
#infected a week and a half ago - some people are still shedding
#if looking at cases you have 3 gammas 
#Cases ~ 2 gamma ~ infected ~ 1 gamma ~ still shedding 
 
#1) Focus on 2 or 3 plots give very clear heuristic picture. in form that does not need words
 
#2)CCF that gives metric behind heuristic
 
#3)
 #FullCase
```
 
 
```{r Ploting Fnc} 
#library(dynlm)

IsFull <- function(DF){
  return(length(DF$Date)==max(DF$Date)-min(DF$Date)+1)
}


```

```{r Madison Prep, fig.height=3}
FullMadLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),"Madison")

SCPDF <- DFSmoothingFNC(FullCase,SiteS="Madison")%>%
  mutate(Site="Madison")

SCPDF2 <- DFSmoothingFNC(FullCase,PreRoll=TRUE,SiteS="Madison")%>%
  mutate(Site="Madison")

SCPDF3 <- inner_join(SCPDF,SCPDF2,by=c("Date","Site","Cases"),suffix=c("",".PreRolled"))
MergedDF <- inner_join(SCPDF3,FullMadLimsDF, by=c("Date","Site"))

MergedDF$LoessN1 <- DFLoessFNC(MergedDF,SiteS="Madison")

MergedDF <- MergedDF%>%
  select(Date,Site,Cases,Cases2,Cases2.PreRolled,N1,LoessN1,N1Error)

TSDF <- ts(MergedDF,start = 18520)
SLDPreRolledVec <- TSDF[,5]
SLDCaseVec <- TSDF[,4]
CaseVec <- TSDF[,3]
loessN1Vec <- TSDF[,7]
logN1Vec <- log(TSDF[,6])

plot(SLDPreRolledVec)
plot(SLDCaseVec)
```


--------------------------

```{r Mad Full Graphic, include=FALSE}
SLDGraphics("Madison",SLDPreRolledVec,loessN1Vec,"SLD","log(N1)")


#library(TSA)
#arimax(SLDCaseVec,order=c(2,1,0),xreg=loessN1Vec)

#7 day weekly average

#instead do regression model of cases by day of week
#changing seasonality
#is model useful
#SARIMA residuals
#cases method
#color coat axis
#fix all labeling inconsistency
#loess
#add cases and 7 day cases and log(N1) to plot
```

```{r}
#asks Nathan for fuller case data
#SLD to pure N1
#logN1 SSD  comp give stats to optimize
#seasonal effect?
#waldtest(SLDModel[,1],SLDModel[,2])

#Pre whiting - auto correlation removing
#
#First diff acts as derivative for perfect smooth
#First diff is hard to interpret with noisy data
#goal is not perfect correlation: goal is to have principled analysis that helps 
#explain what we see to test different changes
#
#is we get something that works great for madison. Nathan will finish


#Rolling correlation -- CCF
#Pre whiting - auto correlation removing
#normalizing by PMMoV - worked at some points but noise in PMMoV hurt
#loess smoothing on PMMoV might help with that
#revisit norm
#revisit N1 N2
#library(lmtest)
```

```{r}

# 
# SLDModelPEight <- SLDGraphics("MMSD-P18",Diffs=1)
# 
# intersect(unique(LIMSFullDF$Site),unique(FullCase$Site))

#great: Madison, P11, P7
#ok: P8
#bad: p18
```


```{r}
# library(tseries)
# #library(dLagM)
# 
# #ts.plot(diff(aba[,1],2),stats::lag(150*diff(aba[,2],2),12),col=c("red","blue"))
# #adf.test(diff(aba[,1],2))
# 
# rolCorPlot(aba[,1],aba[,2],width=7)
# library(tidyquant)
```

```{r}
# library("portes")
# library(TSA)
# SLDTS <- SLDModel[,6]
# N1 <- log(SLDModel[,8])
# LoessN1 <- log(SLDModel[,15])
# auto.arima(diff(LoessN1, seasonal=FALSE,
#   stepwise=FALSE, approximation=FALSE))
# fit2 <- Arima(N1, order=c(1,1,1))
# 
# x <- N1 - fitted(Arima(N1, model = fit2))
# y <- SLDTS - fitted(Arima(SLDTS, model = fit2))
# ccf(x, y)
# 
# ggtsdisplay(x)
# ggtsdisplay(y)
# #prewhiten(N1, SLDTS, x.model = mod1)
# 
# 
# 
# XReg <- do.call(ts.intersect,lapply(1:14,stats::lag,x=LoessN1))
# colnames(XReg) <- 1:14
# MainDriver <- ts.intersect(XReg,SLDTS)
# 
# regmodel=lm(diff(SLDTS)~diff(XReg.14),data=MainDriver)
# summary(regmodel)
# ggtsdisplay(diff(MainDriver[,14]))
# ggtsdisplay(diff(MainDriver[,15]))
# ggtsdisplay(residuals(regmodel))
# 
# ar1res = Arima(residuals(regmodel), order=c(1,0,0))
# xl = ts.intersect(MainDriver[,14], stats::lag(MainDriver[,14],-1))
# xnew=xl[,1] - 0.6488*xl[,2]
# yl = ts.intersect(MainDriver[,15],stats::lag(MainDriver[,15],-1))
# ynew=yl[,1]-0.6488*yl[,2]
#  
# adjustreg = lm(ynew~xnew) # Adjustment regression
# summary(adjustreg)
# ggtsdisplay(residuals(adjustreg))
```

```{r}
# library(forecast)
# library(slider)
# 
# mod1 <- Arima(LoessN1, order=c(4,2,0))
# x <- LoessN1 - fitted(Arima(LoessN1, model = mod1))
# y <- SLDTS - fitted(Arima(SLDTS, model = mod1))
# ccf(x, y)
# ccf(LoessN1,SLDTS)
# ggtsdisplay(x)
# ggtsdisplay(y)
# mod1 <- Arima(LoessN1, order=c(4,2,0))
# 
# 
# ggtsdisplay(diff(LoessN1,differences=2))
# ggtsdisplay(diff(SLDTS,differences=2))
# ccf(diff(LoessN1,differences=2),diff(SLDTS,differences=2))
# 
# 
# 
# XReg <- do.call(ts.intersect,lapply(-10:10,stats::lag,x=LoessN1))
# colnames(XReg) <- -10:10
# MainDriver <- ts.intersect(XReg,SLDTS)
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,1:21]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,1:11]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,11:21]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,15:18]))
# (fit1 <- auto.arima(MainDriver[,22], xreg=MainDriver[,16:18]))
# 
# (fit <- auto.arima(MainDriver[,22], xreg=MainDriver[,15:18]))
# summary(fit)


#library(TSA)
#arimax
```

```{r 6 part plot}
#(SourceDF$N1Error)


TSPloting2(list(SLDPreRolledVec,loessN1Vec,CaseVec),MergedDF,
            SubTitle="Madison",SLD=FALSE)
TSPloting2(list(SLDPreRolledVec,loessN1Vec,CaseVec),MergedDF,
            SubTitle="Madison")



```

-----------------------------------------------


```{r Dorms}
Site="UW-LakeShore"
#UW-Sellery
#UW-LakeShore
FullLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),Site)
SmoothCasePlotDF <- DFSmoothingFNC(FullCase,SiteS=Site,
                                   Weights=c(rep(0,10),
                              dgamma(1:21,
                              scale=scale,
                              shape=shape)[11:21]))

FullLimsDF$LoessN1 <- DFLoessFNC(FullLimsDF,SiteS=Site)

MergedDF <- inner_join(SmoothCasePlotDF,FullLimsDF,
                       by=c("Date","Site"))

MergedDF <- MergedDF%>%
  select(Date,Site,Cases,Cases2,N1,LoessN1,N1Error)

TSDF <- ts(MergedDF,start = 18520)
SLDCaseVec <- TSDF[,4]
CaseVec <- TSDF[,3]
loessN1Vec <- TSDF[,6]
logN1Vec <- log(TSDF[,5])

SLDModelMad <- SLDGraphics(Site,SLDCaseVec,loessN1Vec,"SLD","log(N1)")

TSPloting2(list(SLDCaseVec,loessN1Vec,CaseVec),MergedDF,
            SubTitle=Site,SLD=TRUE)
```
-----------------------------------------

```{r Sell}
DormGraphics <- function(Site,InDepth=FALSE,Short=TRUE){
  FullLimsDF <- DataPrep(LIMSFullDF,keep=c("N1","N1Error"),Site)
  SCPDF <- DFSmoothingFNC(FullCase,SiteS=Site,
                                Weights=c(rep(0,10),
                                dgamma(1:21,
                                scale=scale,
                                shape=shape)[11:21]))
  
  SCPDF2 <- DFSmoothingFNC(FullCase,PreRoll=TRUE,SiteS=Site,
                                Weights=c(rep(0,10),
                                dgamma(1:21,
                                scale=scale,
                                shape=shape)[11:21]))%>%
    mutate(Site=Site)
  
  SCPDF3 <- inner_join(SCPDF,SCPDF2,by=c("Date","Site","Cases"),suffix=c("",".PreRolled"))
  MergedDF <- inner_join(SCPDF3,FullLimsDF, by=c("Date","Site"))
  
  
  MergedDF$LoessN1 <- DFLoessFNC(MergedDF,SiteS=Site)
  
  MergedDF <- MergedDF%>%
    select(Date,Site,Cases,Cases2,Cases2.PreRolled,N1,LoessN1,N1Error)
  
  TSDF <- ts(MergedDF,start = 18520)
  SLDPreRolledVec <- TSDF[,5]
  SLDCaseVec <- TSDF[,4]
  CaseVec <- TSDF[,3]
  loessN1Vec <- TSDF[,7]
  logN1Vec <- log(TSDF[,6])
  if(InDepth){
    SLDModelMad <- SLDGraphics(Site,SLDPreRolledVec,loessN1Vec,"SLD","log(N1)")
  }
  if(Short){
    TSPloting2(list(SLDPreRolledVec,loessN1Vec,CaseVec),MergedDF,
                SubTitle=Site,SLD=TRUE)
  }
  return(TSDF)
}
# plot(SLDPreRolledVec)
# plot(SLDCaseVec)

ListDiscard <- lapply(c("Spring UW-Sellery","Fall UW-Sellery",
         "Spring UW-LakeShore","Fall UW-LakeShore"),DormGraphics)
#Fall UW-Sellery
#UW-LakeShore
```



----------------------------------------------------------------


```{r}
missing_codes <- MissingCode()
LIMSFullDF2 <- read_excel(LIMSFN,
                                  na  =  missing_codes,
                                  col_types = c(rep("guess",48),"text",rep("guess",12)))%>%
  rename(Site=wwtp_name,
         collected=sample_collect_date,
         tested=test_result_date,
         N1=n1_sars_cov2_conc)%>%
  mutate(collected=mdy(collected),
         tested=as.Date(as.POSIXct(tested,format='%m/%d/%Y ')),
         N1=as.numeric(N1),
         TimeDiff=tested-collected)


#sample_collect_date
#sample_collect_time
#test_result_date
#unformatted_collectdate

LIMSFullDF2%>%
  filter(Site=="Madison Metro")%>%
  ggplot()+
  aes(y=N1)+
  geom_point(aes(x=collected,color="col"))+
  geom_point(aes(x=tested,color="Tested"))+
  scale_y_log10()
  
LIMSFullDF2%>%
  filter(Site=="Madison Metro")%>%
  ggplot()+
  aes(y=N1)+
  geom_point(aes(x=TimeDiff,color="col"))+
  #geom_point(aes(x=tested,color="Tested"))+
  scale_y_log10()

LIMSFullDF2%>%
  ggplot()+
  aes(y=TimeDiff)+
  geom_point(aes(x=collected))

LIMSFullDF2%>%
  #filter(TimeDiff<50)%>%
  ggplot()+
  aes(y=TimeDiff)+
  geom_point(aes(x=collected))+
  geom_vline(aes(xintercept =mdy("12-15-2020")))+
  geom_hline(aes(yintercept =80))


LIMSFullDF2%>%
  #filter(TimeDiff<50)%>%
  mutate(Time=ifelse(collected<mdy("12-15-2020"),"Pre2021","2021"))%>%
  group_by(Time)%>%
  summarise(mean=mean(log(N1),na.rm=TRUE),
            var=var(log(N1),na.rm=TRUE),
            meanDif=mean(TimeDiff,na.rm=TRUE),
            varDif=var(TimeDiff,na.rm=TRUE))



Aba=LIMSFullDF2%>%
  mutate(Time=ifelse(collected<mdy("12-15-2020"),"Pre2021","2021"))
summary(aov(N1~Time,data=Aba))

DecayRate=-0.041

LIMSFullDF2%>%
  filter(Site=="Madison Metro")%>%
  mutate(N1P=N1*exp(1)^(.041*as.numeric(TimeDiff)))%>%
  mutate(Outliers=ifelse(TimeDiff>12,"Long delay","Normal delay"))%>%
  ggplot()+
  aes(x=collected)+#,color=Outliers)+
  geom_point(aes(y=N1,color="N1"),alpha=.3)+
  geom_point(aes(y=N1P,color="N1 undecayed"),alpha=.3)+
  geom_smooth(aes(y=N1,color="N1"),se=FALSE,span=.2)+
  geom_smooth(aes(y=N1P,color="N1 undecayed"),se=FALSE,span=.2)+
  scale_y_log10()

```


