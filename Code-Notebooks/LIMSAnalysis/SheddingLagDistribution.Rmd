---
title: "SheddingLagDistribution"
author: "Marlin"
date: "7/22/2021"
output: html_document
---

```{r set up markdown settings, echo=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)

```

```{r Start enviroment, message=FALSE, warning=FALSE}
library(ggpubr)
library(dplyr)
library(forecast)
library(lmtest)
library(lubridate)
library(limma)
library(zoo)

#Data Files and prep work
source("../../Scripts/GenPlotMaking.R")
source("../../Scripts/WasteWaterDataProccess.R")
source("../../Scripts/CassesDataProccess.R")
source("../../Scripts/HelperFunctions.R")
```


```{r DF Set Up}
PathStarter="Z:/"

LatMMSDFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/MMSD_Cases.csv")
LIMSFN <- paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/WATERMICRO_WW_COVID-2021-06-30 17 40.xlsx")

HFGCasesFN  <-  paste0(PathStarter,"COVID-19_WastewaterAnalysis/data/raw/HighFreq_CaseData_2021-05-07.csv")


LatCaseDF <- CovidDataPARSER(MMSDFN = LatMMSDFN)%>%
  filter(!is.na(Site))%>%
  select(Date,Site,Cases,Tests,Per_pos)

HFGCaseDF <- HFGCasesPARSER(FN = HFGCasesFN)%>%
  filter(!is.na(Site))%>%
  mutate(Tests=NA,Per_pos=NA)%>%
  select(Date,Site,Cases=ReportedCases,Tests,Per_pos)%>%
  mutate(Cases = ifelse(Cases==-999,2.5,Cases))%>%
  filter(Site!="Madison")

FullCase <- rbind(HFGCaseDF,LatCaseDF)

LIMSFullDF <- LIMSDataPARSER(LIMSFN)%>%
  select(Date,Site, BCoV, N1,N1Error,N2, N2Error,PMMoV,Pop,FlowRate)

CaseSum=FullCase%>%
  filter(!is.na(Cases))%>%
  group_by(Site)%>%
  summarise(NCase=n())

N1Sum=LIMSFullDF%>%
  filter(!is.na(N1))%>%
  group_by(Site)%>%
  summarise(NN1=n())

DataComp <- inner_join(CaseSum,N1Sum,by=c("Site"))%>%
  mutate(Dif=NCase-NN1,min=ifelse(NCase<NN1,NCase,NN1))
LowCaseDataPoints <- DataComp%>%
  filter(Dif<0)
```
```{r CaseSmoothing}
#return( RollPerPos(CaseDF,"Cases","Tests",Facet="Site"))
library(limma)

DFSmoothingFNC <- function(CaseDF){
  #5.028338
  scale =5.028338
  #2.332779
  shape =2.332779
  FullDayDF <- data.frame(Date=seq(min(CaseDF$Date),max(CaseDF$Date),1))
  FullDateDF <- full_join(FullDayDF,CaseDF, by = c("Date"))%>%
    fill(Cases, .direction = "down")%>%
    group_by(Site)%>%
    mutate(Cases2 = c(rep(NA,20),
                    rollapply(Cases,width=21,FUN=weighted.mean,
                          w=dgamma(1:21,scale =scale,shape =shape),
                          na.rm = TRUE)))
}

DFLoessFNC <- function(LimsDF){
    FullDayDF <- data.frame(Date=seq(min(LimsDF$Date),max(LimsDF$Date),1))
    ReadyDF <- full_join(FullDayDF,LimsDF, by = c("Date"))%>%
      fill(N1, .direction = "down")
    
    loessFit(y=log(ReadyDF$N1),
             x=ReadyDF$Date,
             span=.125,
             min.weight=0,
             max.weight=1e5,
             iterations=20)$fitted
}

  #5.028338
scale =5.028338
  #2.332779
shape =2.332779
  
plot(dgamma(1:21,scale =scale,shape =shape), 
            main="Gamma Distribution with mean = 11.73 days and SD = 7.68",
            ylab = "Weight",
            xlab = "Lag")

```


```{R TSPliting}

#library(smooth)
#sma(MergedDF[,8], h=7)

# fit = Arima(CasesTSVec, xreg=loessPred, order=c(2,1,0))
# 
# cbind("Regression Errors" = residuals(fit, type="regression"),
#       "ARIMA errors" = residuals(fit, type="innovation")) %>%
#   autoplot(facets=TRUE)
# checkresiduals(fit)
#
 

#alt y axis
#x axis labled as date
#control color so they are not so light
#2)Show original data as bar graph?
#Make it clear its Madison/Title that explains
#few people have done SLD
```

```{r Formal Work, include=FALSE}
# IndependentVec <- diff(loessPred)
# DependentVec <- diff(CasesTSVec)
# 
# ccfvalues2  <-  ccf(IndependentVec,DependentVec,type = c("correlation"),na.action = na.pass)
# ccfvalues2  <-  ccf(loessPred,CasesTSVec,type = c("correlation"),na.action = na.pass)
# 
# alldata1 <- ts.union(Pred = diff(CasesTSVec),N1Norm = diff(loessPred),
#                          N1TSVec,
#                          N1A=stats::lag(diff(loessPred),1),
#                          N1B=stats::lag(diff(loessPred),10),
#                          N1C=stats::lag(diff(loessPred)))
# 
# 
# tryit1a  <- lm(Pred~N1B, data = alldata1)
# 
# summary(tryit1a)
# #plot(tryit1a)
# acf(residuals(tryit1a))
```

```{r}
#Do for non interceptor data
 
#Transformation to stabilize scale
 
 
#1)Make overlay plot function
#a)normal comp
#b)first difference
#c)P8 version
#compare smooth vs Smooth  ccf
#show all smooth Unsmooth combos
#look for best gamma
 
 
#CCF
#broke it into 2 parts
#CCF of SLD vs raw N1
 
#ccf(CasesTSVec,)
 
#some pipeline to optimize
#What did the original paper do? are we doing the same thing
#case reported at day A
#What we want: when person A became infected
#What we expect: SLD leads Cases
#infected a week and a half ago - some people are still shedding
#if looking at cases you have 3 gammas 
#Cases ~ 2 gamma ~ infected ~ 1 gamma ~ still shedding 
 
#1) Focus on 2 or 3 plots give very clear heuristic picture. in form that does not need words
 
#2)CCF that gives metric behind heuristic
 
#3)
 #FullCase
```
 
 
```{r Ploting Fnc} 
library(dynlm)

IsFull <- function(DF){
  return(length(DF$Date)==max(DF$Date)-min(DF$Date)+1)
}

TSPloting <- function(PlotingTS,SourceDF,FullPlot=TRUE,SubTitle=NA){
  par(mar = c(5, 4, 4, 4) + 0.3)           

  if(FullPlot){
    plot.ts(rollmean(exp(PlotingTS[[4]]), 7,align="right",fill = NA),
            col = "steelblue3", 
            main="SLD compared to Loess smoothing of N1",
            sub=SubTitle,
            ylab = "N1 (GC/L)",log = 'y',xaxt = "n")
    
    par(new = TRUE)  
    plot.ts(rollmean(PlotingTS[[3]], 7,align="right",fill = NA),
            col = "hotpink",        
       axes = FALSE, xlab = "", ylab = "",xaxt = "n")
    
    par(new = TRUE)  
    plot.ts(exp(PlotingTS[[2]]),
            col = "blue",        
       axes = FALSE, 
       xlab = "", 
       ylab = "",
       log = 'y',xaxt = "n")
  }else{
    plot.ts(PlotingTS[[2]], 
          col = "blue", 
          ylab = "N1 (GC/L)", 
          main="First Diffrence of SLD and Loess smoothing of N1",
          sub=SubTitle,
          xaxt = "n")
  }

  par(new = TRUE)                           
  plot.ts(PlotingTS[[1]], col = "red",        
     axes = FALSE, xlab = "", ylab = "",xaxt = "n")

  axis(side = 4, at = pretty(range(PlotingTS[[1]])))   
  mtext("Cases", side = 4, line = 3)
  if(FullPlot){
    legendNames <- c("SLD Cases","7 MA Cases","Loess Smoothing","7 MA N1")
    legendColors <- c("red","hotpink","blue", "steelblue3")
  }else{
    legendNames<- c("SLD Cases","Loess Smoothing")
    legendColors<- c("red","blue")
  }
  legend("topright", legend=legendNames, col=legendColors, lty=1, cex=.75)
  axis(1,
     pretty(SourceDF$Date),labels =format(pretty(SourceDF$Date), "%Y-%m-%d"))
     #pretty(format(SourceDF$Date, "%Y-%m-%d")))
}


SLDGraphics <- function(SiteS,Diffs=1){
  FilteredLIMSDF <- filter(LIMSFullDF,Site==SiteS)
  
  FullDayDF <- data.frame(Date=seq(min(FilteredLIMSDF$Date),
                                   max(FilteredLIMSDF$Date),1))
  
  ReadyDF <- full_join(FullDayDF,FilteredLIMSDF, by = c("Date"))%>%
    fill(N1, .direction = "down")%>%
    mutate(Site=SiteS)
  
  SmoothCasePlotDF <- DFSmoothingFNC(filter(FullCase,Site==SiteS))%>%
    mutate(Site=SiteS)#%>%
    #filter(!is.na(Cases2))

  MergedDF <- inner_join(SmoothCasePlotDF,ReadyDF, by=c("Date","Site"))
  #return(MergedDF)
  MergedDF$LoessN1 <- DFLoessFNC(MergedDF)
  #return(MergedDF)
  #ts(MergedDF)[,6]
  TSDF <- ts(MergedDF,start = 18520)
  SLDCaseVec <- TSDF[,6]
  CaseVec <- TSDF[,3]
  loessN1Vec <- TSDF[,15]
  logN1Vec <- log(TSDF[,8])
  #return(loessN1Vec)
  TSPloting(list(SLDCaseVec,loessN1Vec,CaseVec,logN1Vec),MergedDF,SubTitle=SiteS)
  CCF1 <- ccf(loessN1Vec,
               SLDCaseVec,
               main="Cross correlation between SLD and loess smoothing of N1",
               sub=SiteS)
  
  TSPloting(list(diff(SLDCaseVec,Diffs),diff(loessN1Vec,Diffs)),MergedDF,
            FullPlot=FALSE,SubTitle=SiteS)
  
  CCF2 <- ccf(diff(loessN1Vec,Diffs),
               diff(SLDCaseVec,Diffs),
               main="CC between first diffrence of SLD and smoothed N1",
               sub=SiteS)
  
  CCF3 <- ccf(logN1Vec,
               SLDCaseVec,
               main="CC between  SLD and log of N1",
               sub=SiteS)
  
  CCF4 <- ccf(loessN1Vec,
               CaseVec,
               main="CC between Cases and loess smoothing of N1",
               sub=SiteS)
  #return(Plot3)
  TSUnionDF <- ts.union(SLDCaseVec,
                        OGVec = loessN1Vec)
  FullModel <- dynlm(SLDCaseVec~L(loessN1Vec,c(-12)),data=TSUnionDF)
  return(TSDF)
}
```


```{r Madison}

SLDModel <- SLDGraphics("Madison",Diffs=1)
summary(SLDModel)
#asks Nathan for fuller case data
#SLD to pure N1
#logN1 SSD  comp give stats to optimize
#seasonal effect?
#waldtest(SLDModel[,1],SLDModel[,2])

#Pre whiting - auto correlation removing
#
#First diff acts as derivative for perfect smooth
#First diff is hard to interpret with noisy data
#goal is not perfect correlation: goal is to have principled analysis that helps 
#explain what we see to test different changes
#
#is we get something that works great for madison. Nathan will finish


#Rolling correlation -- CCF
#Pre whiting - auto correlation removing
#normalizing by PMMoV - worked at some points but noise in PMMoV hurt
#loess smoothing on PMMoV might help with that
#revisit norm
#revisit N1 N2

```
```{r}


SLDModel <- SLDGraphics("MMSD-P18",Diffs=1)
summary(aba)

intersect(unique(LIMSFullDF$Site),unique(FullCase$Site))

#great: Madison, P11, P7
#ok: P8
#bad: p18
```


```{r}
library(tseries)
#library(dLagM)

#ts.plot(diff(aba[,1],2),stats::lag(150*diff(aba[,2],2),12),col=c("red","blue"))
#adf.test(diff(aba[,1],2))

rolCorPlot(aba[,1],aba[,2],width=7)
library(tidyquant)
```

```{r}
library("portes")
SLDTS <- SLDModel[,6]
N1 <- log(SLDModel[,8])
auto.arima(N1, seasonal=FALSE,
  stepwise=FALSE, approximation=FALSE)
fit2 <- Arima(N1, order=c(1,1,1))
ggtsdisplay(N1)
checkresiduals(fit2)
FitResid <- residuals(fit2)

newpwy<- stats::filter(SLDTS, filter = c(0.4981  ,1,-0.8995), sides =1)
ccf (FitResid,newpwy,na.action=na.omit)
```


