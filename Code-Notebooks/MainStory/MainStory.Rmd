---
params:
  BaseDir: "Z:/"
  ##BaseDir: "/Volumes/byandell/"
  RemoveOutliers: TRUE
title: "MainStory"
author: "Marlin"
date: "10/28/2021"
output: 
  html_document: 
    fig_width: 6
    fig_height: 4
---

Overview

There is mainly 3 parts to this story:

1) A simple easy to communicate model of the key relationship

2) A medium complexity smoothing analysis

3) A full power time series analysis with causal inference


The two data set used in this analysis are the Madison case and waste water concentration data.

```{r set up markdown settings, echo=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE
)
```


```{r Start enviroment, message=FALSE, warning=FALSE, echo=FALSE}
library(ggpubr)
library(forecast)
library(lmtest)
library(lubridate)
library(limma)
library(zoo)
library(readxl)
library(dplyr)
library(plotly)
  #library(lintr)


#Data Files and prep work
source("../../lib/GenPlotMaking.R")
source("../../lib/DataProccess.R")
source("../../lib/HelperFunctions.R")
source("../../lib/NoTSCorrelationFunctions.R")
```

```{r DF Set Up, echo=FALSE}
BaseDir <- params$BaseDir#get the root of the directory where the data is stored

#All the Madison data is contained in these two files
MadisonCaseFN  <-  paste0(BaseDir, "COVID-19_WastewaterAnalysis/data/processed/MMSD_Cases_processed.csv")
LIMSFN <- paste0(BaseDir, "COVID-19_WastewaterAnalysis/data/processed/LIMSWasteData_2021-06-30_17-40.csv")


#Importing the Madison case data
LatCaseDF <- ParseData(MadisonCaseFN)%>% 
  filter(Site == "Madison")%>%
  select(Date, Site, Cases)

#Importing the Madison waste water data
LIMSFullDF <- ParseData(LIMSFN)%>%
  filter(Site == "Madison")%>%
  select(Date, Site,  N1, N1Error)

#joining the two data frames together
FullDF <- full_join(LatCaseDF,LIMSFullDF, by = c("Date","Site"))

#what does the data look like? 
tail(FullDF)
```

A simple display of the data shows the core components of this story. First that both data sets are extremely noisy.
And that there is a hint of a relationship between the two signals. 

```{r plot of base relationship}
MinMaxNorm <- function(Vec){#normalizes the data to range from 0 and 1
  normVec <- (Vec-min(Vec,na.rm=TRUE))/max(Vec,na.rm=TRUE)
  return(normVec)
}

NoNa <- function(DF,...){#Removes NA from the reverent columns
  ColumnNames <- c(...)
  NoNaDF <- DF%>%
    filter(
      across(
      .cols = ColumnNames,
      .fns = ~ !is.na(.x))
      )
  return(NoNaDF)
}

FirstImpression <- FullDF%>%
  NoNa("N1","Cases")%>%#Removing outliers
  ggplot(aes(x=Date))+#Data depends on time
  geom_line(aes(y=MinMaxNorm(N1), color="N1",info=N1))+#compares N1 to Cases
  geom_line(aes(y=MinMaxNorm(Cases), color="Cases",info=Cases))+
  labs(y="variable min max normalized")

ggplotly(FirstImpression,tooltip=c("info","Date"))
```





`r if(params$RemoveOutliers){"From a first pass it is clear that the waste water measurements before 11/20/2020 did not function as an effective measure of the amount of waste water shed in the community. So for this analysis we are removing waste water data from before that point. Also there are some extreme outliers that we remove for more effective analysis"}`


```{r remove unusual N1 data points,eval = params$RemoveOutliers,echo = FALSE}
IntermediateOutlierGraphic <- FALSE

DaySmoothed=21#Very wide smoothing to find where the data strong deviate from trend

FullDF2 <- FullDF%>%
  mutate(N1 = ifelse(Date < mdy("11/20/2020"),NA,N1))

FullDF3 <- FullDF2%>%#Remove older data that clearly has no relationship to Cases
  mutate(SmoothN1=rollapply(data = N1, width = DaySmoothed, FUN = median, 
                            na.r = TRUE,fill=NA),#Finding very smooth version of the data with no outliers
         SmoothN1=ifelse(is.na(SmoothN1),N1,SmoothN1),#Fixing issue where rollapply fills NA on right border
         LargeError=N1>1.5*SmoothN1,#Calculating error Limits
         N1=ifelse(LargeError,SmoothN1,N1))%>%#replacing data points that variance is to large
  select(-SmoothN1)#Removing unneeded calculated columns

if(IntermediateOutlierGraphic){
  OutlierGraphic <- FullDF%>%
    mutate(SmoothN1=rollapply(data = N1, width = DaySmoothed, FUN = median, 
                            na.r = TRUE,fill=NA),#creating smooth data
           SmoothN1=ifelse(is.na(SmoothN1),N1,SmoothN1))%>%#Fixing issue where rollapply fills NA on right border)%>%
    mutate(Outliers=Date < mdy("11/20/2020")|N1>1.5*SmoothN1)%>%
    NoNa("N1","Cases")%>%#Removing outliers
    ggplot(aes(x=Date))+#Data depends on time
    geom_point(aes(y=MinMaxNorm(N1), color="N1",shape=Outliers,info=N1))+#compares N1 to Cases
    geom_point(aes(y=MinMaxNorm(Cases), color="Cases",info=Cases))+
    labs(y="variable min max normalized")
  ggplotly(OutlierGraphic,tooltip=c("info","Date"))
}


FullDF3%>%
  NoNa("N1","Cases")%>%#Removing outliers
  ggplot(aes(x=Date))+#Data depends on time
  geom_line(aes(y=MinMaxNorm(N1), color="N1"))+#compares N1 to Cases
  geom_line(aes(y=MinMaxNorm(Cases), color="Cases"))+
  labs(y="variable min max normalized")
```





A key component to this relationship is that the relationship between N1 and Case involves a gamma distribution modeling both the time between catching Covid-19 and getting a test and the concentration of the shedded particles. We found a gamma distribution with mean 11.73 days and a sd of 7.68 match's other research and gives good results.

```{r SLD}
SLDWidth <- 21
scale  <- 5.028338
shape  <- 2.332779 #These parameters are equivalent to the mean and sd above

weights <- dgamma(1:SLDWidth, scale = scale, shape = shape)
plot(weights,  
            main=paste("Gamma Distribution with mean = 11.73 days,and SD = 7.68"), 
            ylab = "Weight", 
            xlab = "Lag")

SLDSmoothedDF <- FullDF3%>%
  mutate(
    SLDCases = c(rep(NA,SLDWidth-1),#elimination of starting values not relevant as we have a 50+ day buffer of case data
                        rollapply(Cases,width=SLDWidth,FUN=weighted.mean,
                                  w=weights,
                                  na.rm = FALSE)))#no missing data to remove


SLDSmoothedDF%>%
  NoNa("N1","SLDCases")%>%#same plot as earlier but with the SLD smoothing
  ggplot(aes(x=Date))+
  geom_line(aes(y=MinMaxNorm(SLDCases), color="SLDCases"))+
  geom_line(aes(y=MinMaxNorm(N1), color="N1"))+
  facet_wrap(~Site)+
  labs(y="variable min max normalized")
```


To isolate this relationship we used a primitive binning relationship. This clarifies the relationship we see hints of in the previous graphic and masks the noise in the data. 


```{r binning part}
medianMean <- function(Vec){
  return(mean(replace(Vec, c(which.min(Vec), which.max(Vec)), NA), na.rm = TRUE))
}

StartDate <- 1
DaySmoothing <- 14
Lag <- 4

BinDF <- SLDSmoothedDF%>%
  select(Date, SLDCases, N1)%>%
    mutate(MovedCases = data.table::shift(SLDCases, Lag), 
           Week=(as.numeric(Date)+StartDate)%/%DaySmoothing)%>%
  group_by(Week)%>%
  #filter(Week>2670)%>%
  summarise(BinnedCases=mean(MovedCases, na.rm=TRUE), BinnedN1=exp(mean(log(N1), na.rm=TRUE)))



BinDF%>%
  ggplot()+
  geom_line(aes(x=Week, y=MinMaxNorm(BinnedN1), color="N1"))+
  geom_line(aes(x=Week, y=MinMaxNorm(BinnedCases), color="Cases"))+
  labs(y="Binned variable min max normalized")

BinDF%>%
  ggplot()+
  geom_point(aes(x=BinnedCases, y=BinnedN1))

cor(BinDF$BinnedN1, BinDF$BinnedCases, use="pairwise.complete.obs")
summary(lm(BinnedCases~BinnedN1, data=BinDF))
```




To generate this relationship without reducing the amount of data we rely on a Loess smoothing of the data. The first step is to get a more rigorous measure of the relationship of the data. Here we will use cross correlation. These figures support the work done in previous steps.

```{r ccf on previous data structures}
ccf(SLDSmoothedDF$Cases, SLDSmoothedDF$N1, na.action=na.pass)

ccf(SLDSmoothedDF$SLDCases, SLDSmoothedDF$N1, na.action=na.pass)

ccf(BinDF$BinnedCases, BinDF$BinnedN1, na.action=na.pass)
```
The loess smoothing is a way of generating smooth curves from noisy data. The displayed plot shows the visual power of this smoothing. We see a relationship in the big patterns but also multiple sub patterns match. We see in general that smoothed N1 both lags and leads the case data.

```{r loess smoothing and some intro CCF processes}
SLDSmoothedDF$loessN1 <- loessFit(y=(SLDSmoothedDF$N1), 
                      x=SLDSmoothedDF$Date, 
                      span=.2, 
                      iterations=2)$fitted


SLDSmoothedDF%>%
  NoNa("loessN1","SLDCases")%>%
  ggplot()+
  geom_line(aes(x=Date, y=MinMaxNorm(loessN1), color="loessN1"))+
  geom_line(aes(x=Date, y=MinMaxNorm(SLDCases), color="SLDCases"))+
  facet_wrap(~Site)+
  labs(y="variable min max normalized")




ccf(SLDSmoothedDF$loessN1, SLDSmoothedDF$SLDCases, na.action=na.pass)
```


```{r example, Ignore for now obvs, eval = FALSE}

input <- initialize data
          loess
          SLD smooth
          
Analysis <- plot
Analysis <- CCF
```

